{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04w3OowXkaQh"
      },
      "source": [
        "# Using Quantization Aware Training in TensorFlow\n",
        "\n",
        "In this tutorial, we will discuss how to train a Quantization Aware Model using TensorFlow Model Optimization Toolkit (TF-MOT). Quantization Aware Training allows for reduced precision representations of weights and, optionally, activations for both storage and computation. This is particularly important for deploying models on hardware and platforms that don't support floating point operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Sfci39Llvii",
        "outputId": "443499bf-8386-469a-8524-e8ad574944dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /Users/raphael/anaconda3/lib/python3.10/site-packages (1.23.5)\n",
            "Requirement already satisfied: tensorflow in /Users/raphael/anaconda3/lib/python3.10/site-packages (2.13.0rc1)\n",
            "Requirement already satisfied: tensorflow_model_optimization in /Users/raphael/anaconda3/lib/python3.10/site-packages (0.7.5)\n",
            "Requirement already satisfied: matplotlib in /Users/raphael/anaconda3/lib/python3.10/site-packages (3.7.0)\n",
            "Requirement already satisfied: tensorflow-macos==2.13.0-rc1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow) (2.13.0rc1)\n",
            "Requirement already satisfied: packaging in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (22.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.23.2)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (23.5.26)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1rc0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.1rc0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (4.4.0)\n",
            "Requirement already satisfied: setuptools in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (65.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0rc0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0rc0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.54.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (16.0.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.13.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow-macos==2.13.0-rc1->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorflow_model_optimization) (0.1.8)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.13.0-rc1->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.2.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.19.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.28.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: urllib3<2.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.26.14)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (2.1.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /Users/raphael/anaconda3/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-macos==2.13.0-rc1->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install numpy tensorflow tensorflow_model_optimization matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKiq8oKxklon"
      },
      "source": [
        "## Dataset Preparation\n",
        "We will use the popular MNIST dataset for this example. First, let's import the required libraries and load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4po2PWTAkWOR"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXigQHM_k0ux"
      },
      "source": [
        "We have a total of 70,000 grayscale images, each with a dimension of 28 x 28 pixels. 60,000 images are for training and the remaining 10,000 are for testing.\n",
        "\n",
        "Now, we need to preprocess our data. We need to flatten our data and then normalize it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6AwxawnnkaA5"
      },
      "outputs": [],
      "source": [
        "from scipy.ndimage import zoom\n",
        "\n",
        "# Resizing function\n",
        "def resize_images(images):\n",
        "    return np.array([zoom(image, 0.5) for image in images])\n",
        "\n",
        "# Resize\n",
        "x_train = resize_images(x_train)\n",
        "x_test = resize_images(x_test)\n",
        "\n",
        "# Then reshape\n",
        "x_train = x_train.reshape(60000, 14*14)\n",
        "x_test = x_test.reshape(10000, 14*14)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# normalize to range [0, 1]\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix3qnUgElDlB"
      },
      "source": [
        "## Model Definition and Training\n",
        "We will use a simple feedforward neural network (also known as Multi-layer Perceptron) for this task. Our model will have two hidden layers each with 256 neurons."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7gilDCS6k9-u"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.InputLayer(input_shape=(14*14,)), # Note the input shape should be 14*14 not 196\n",
        "    keras.layers.Dense(10, activation='relu'), \n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', \n",
        "              loss='sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFUZZOudlQmP"
      },
      "source": [
        "Now let's train this model on our training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjkH102GlOd2",
        "outputId": "e872c568-6141-4c70-e070-bc552317f9b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.8076 - accuracy: 0.7770 - val_loss: 0.3906 - val_accuracy: 0.8952\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.3720 - accuracy: 0.8960 - val_loss: 0.3154 - val_accuracy: 0.9093\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 1s 782us/step - loss: 0.3207 - accuracy: 0.9078 - val_loss: 0.2860 - val_accuracy: 0.9172\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 1s 817us/step - loss: 0.2961 - accuracy: 0.9150 - val_loss: 0.2685 - val_accuracy: 0.9234\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 1s 787us/step - loss: 0.2811 - accuracy: 0.9187 - val_loss: 0.2619 - val_accuracy: 0.9227\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 1s 790us/step - loss: 0.2713 - accuracy: 0.9215 - val_loss: 0.2519 - val_accuracy: 0.9268\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 1s 773us/step - loss: 0.2635 - accuracy: 0.9242 - val_loss: 0.2468 - val_accuracy: 0.9287\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 1s 773us/step - loss: 0.2580 - accuracy: 0.9256 - val_loss: 0.2437 - val_accuracy: 0.9290\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 1s 783us/step - loss: 0.2524 - accuracy: 0.9262 - val_loss: 0.2428 - val_accuracy: 0.9295\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 1s 770us/step - loss: 0.2484 - accuracy: 0.9279 - val_loss: 0.2387 - val_accuracy: 0.9304\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "history = model.fit(x_train, y_train,\n",
        "                    epochs=epochs,\n",
        "                    validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNRdKGpflar4"
      },
      "source": [
        "At this point, we have trained a regular model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bu55FCqlbj4"
      },
      "source": [
        "## Making the Model Quantization Aware\n",
        "Now, let's transform our model into a quantization aware model. We use the TensorFlow Model Optimization Toolkit for this.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAZYo9vKlTHK",
        "outputId": "cbe04409-a767-44b9-db3c-be8b043d33cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " quantize_layer (QuantizeLa  (None, 196)               3         \n",
            " yer)                                                            \n",
            "                                                                 \n",
            " quant_dense (QuantizeWrapp  (None, 10)                1975      \n",
            " erV2)                                                           \n",
            "                                                                 \n",
            " quant_dense_1 (QuantizeWra  (None, 10)                115       \n",
            " pperV2)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2093 (8.18 KB)\n",
            "Trainable params: 2080 (8.12 KB)\n",
            "Non-trainable params: 13 (52.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "# Apply quantization to the layers\n",
        "quantize_model = tfmot.quantization.keras.quantize_model\n",
        "\n",
        "# q_aware stands for 'quantization aware'\n",
        "q_aware_model = quantize_model(model)\n",
        "\n",
        "# 'quantize_model' requires a recompile\n",
        "q_aware_model.compile(optimizer='adam',\n",
        "                      loss='sparse_categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "q_aware_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYPUWWwTl_np"
      },
      "source": [
        "We have now created a new model, q_aware_model, which is a quantization aware version of our original model. Now we can train this model exactly like our original model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-t5MPhGlqoI",
        "outputId": "8d0d687f-0af2-44be-fad8-b9da86a20ce1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 2s 1ms/step - loss: 0.2506 - accuracy: 0.9269 - val_loss: 0.2402 - val_accuracy: 0.9303\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 1s 966us/step - loss: 0.2419 - accuracy: 0.9291 - val_loss: 0.2333 - val_accuracy: 0.9323\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 1s 949us/step - loss: 0.2390 - accuracy: 0.9310 - val_loss: 0.2324 - val_accuracy: 0.9327\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 1s 959us/step - loss: 0.2358 - accuracy: 0.9308 - val_loss: 0.2334 - val_accuracy: 0.9342\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 1s 954us/step - loss: 0.2334 - accuracy: 0.9314 - val_loss: 0.2311 - val_accuracy: 0.9324\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 1s 952us/step - loss: 0.2317 - accuracy: 0.9319 - val_loss: 0.2317 - val_accuracy: 0.9351\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 1s 992us/step - loss: 0.2301 - accuracy: 0.9327 - val_loss: 0.2284 - val_accuracy: 0.9355\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 1s 989us/step - loss: 0.2279 - accuracy: 0.9334 - val_loss: 0.2240 - val_accuracy: 0.9358\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 1s 954us/step - loss: 0.2263 - accuracy: 0.9339 - val_loss: 0.2250 - val_accuracy: 0.9364\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 1s 962us/step - loss: 0.2247 - accuracy: 0.9344 - val_loss: 0.2232 - val_accuracy: 0.9359\n",
            "Test loss: 0.22472822666168213\n",
            "Test accuracy: 0.9348999857902527\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "epochs = 10\n",
        "history = q_aware_model.fit(x_train, y_train,\n",
        "                            epochs=epochs,\n",
        "                            validation_split=0.2)\n",
        "\n",
        "scores, acc = q_aware_model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', scores)\n",
        "print('Test accuracy:', acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhbweTQEmWN-"
      },
      "source": [
        "## Converting to TFLite Format\n",
        "Now, we will convert our model to TFLite format, which is a format optimized for on-device machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOwZiCRWmHDT",
        "outputId": "da138eac-0897-4a9e-eff0-4840fc13d035"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/y0/97f_vm5j41z458vgrn6h2xd40000gn/T/tmp3d_qx4i2/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/y0/97f_vm5j41z458vgrn6h2xd40000gn/T/tmp3d_qx4i2/assets\n",
            "/Users/raphael/anaconda3/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:887: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "2023-05-31 18:18:18.332085: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
            "2023-05-31 18:18:18.332115: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
            "2023-05-31 18:18:18.332449: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /var/folders/y0/97f_vm5j41z458vgrn6h2xd40000gn/T/tmp3d_qx4i2\n",
            "2023-05-31 18:18:18.333549: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
            "2023-05-31 18:18:18.333560: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /var/folders/y0/97f_vm5j41z458vgrn6h2xd40000gn/T/tmp3d_qx4i2\n",
            "2023-05-31 18:18:18.336550: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
            "2023-05-31 18:18:18.338055: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
            "2023-05-31 18:18:18.384329: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /var/folders/y0/97f_vm5j41z458vgrn6h2xd40000gn/T/tmp3d_qx4i2\n",
            "2023-05-31 18:18:18.397947: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 65498 microseconds.\n",
            "2023-05-31 18:18:18.425499: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4312"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create a converter\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "\n",
        "# Indicate that you want to perform default optimizations,\n",
        "# which include quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "# Define a generator function that provides your test data's numpy arrays\n",
        "def representative_data_gen():\n",
        "  for i in range(500):\n",
        "    yield [x_test[i:i+1]]\n",
        "\n",
        "# Use the generator function to guide the quantization process\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# Ensure that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# Set the input and output tensors to int8\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# Convert the model\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(\"q_aware_model.tflite\", \"wb\").write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxGWitSs3MAH"
      },
      "source": [
        "## Testing the Quantized Model\n",
        "Now that we have trained a quantization-aware model and converted it to the TFLite format, we can now perform inference using the TensorFlow Lite interpreter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sXEM3WEv3SSt"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        }
      ],
      "source": [
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
        "interpreter.allocate_tensors()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qbfjJFa3Zy7"
      },
      "source": [
        "We first load the TFLite model and allocate the required tensors. The Interpreter class provides methods for loading a model and running inferences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T7r8JFTC3Xxe"
      },
      "outputs": [],
      "source": [
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mP6WRo1L3dZp"
      },
      "source": [
        "Next, we get the details of the input and output tensors. Each tensor in a TensorFlow Lite model has a name, index, shape, data type, and quantization parameters. These can be accessed via the input_details and output_details methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-1yOJjl83b9i"
      },
      "outputs": [],
      "source": [
        "# Normalize the input value to int8\n",
        "input_shape = input_details[0]['shape']\n",
        "input_data = np.array(x_test[0:1], dtype=np.int8)\n",
        "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "\n",
        "# Perform the inference\n",
        "interpreter.invoke()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofFMDXq13ix7"
      },
      "source": [
        "Before performing the inference, we need to normalize the input to match the data type of our model's input tensor, which in our case is int8. Then, we use the set_tensor method to provide the input data to the model. We perform the inference using the invoke method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtfTBPCl3iKm",
        "outputId": "a16ac7eb-d50c-44c7-8a51-0924ebe41473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-128 -128   99  -99 -128 -128 -128 -128 -128 -128]]\n"
          ]
        }
      ],
      "source": [
        "# Get the result\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "print(output_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge-Y3K1J3oWs"
      },
      "source": [
        "After the inference, we get the output data from the model's output tensor.\n",
        "\n",
        "Now, we are going to run the inference for the entire test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B5fDA1Vt3num"
      },
      "outputs": [],
      "source": [
        "(_, _), (x_test_image, y_test_label) = mnist.load_data()\n",
        "\n",
        "# Resize and Normalize x_test_image to int8\n",
        "x_test_image = resize_images(x_test_image)\n",
        "x_test_image_norm = (x_test_image / 255.0 * 255 - 128).astype(np.int8)\n",
        "\n",
        "# Initialize an array to store the predictions\n",
        "predictions = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO9fwtAF3sRP"
      },
      "source": [
        "We normalize the entire test set and initialize an array to store the predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "z1Clh4Kt3fuF"
      },
      "outputs": [],
      "source": [
        "# Iterate over the test data and make predictions\n",
        "for i in range(len(x_test_image_norm)):\n",
        "    test_image = np.expand_dims(x_test_image_norm[i].flatten(), axis=0)\n",
        "    \n",
        "    # Set the value for the input tensor\n",
        "    interpreter.set_tensor(input_details[0]['index'], test_image)\n",
        "    \n",
        "    # Run the inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    output = interpreter.get_tensor(output_details[0]['index'])\n",
        "    predictions.append(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1PzXSuj3uy9"
      },
      "source": [
        "We then iterate over the test set, making predictions for each image. For each image, we flatten the image, normalize it, and then expand its dimensions to match the shape of our model's input tensor.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5wWyve_E3uL8",
        "outputId": "465afb87-ee21-43ad-81e0-ee4d544cc2dd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x1400 with 25 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_labels_prediction(images,labels,idx,num=10):\n",
        "    fig=plt.gcf()\n",
        "    fig.set_size_inches(12, 14)\n",
        "    if num > 25: num=25\n",
        "    for i in range(0, num):\n",
        "        ax=plt.subplot(5, 5, i+1)\n",
        "        ax.imshow(images[idx], cmap='binary')\n",
        "        title=\"label=\" + str(labels[idx])\n",
        "        ax.set_title(title, fontsize=10)\n",
        "        ax.set_xticks([]);\n",
        "        ax.set_yticks([]);\n",
        "        idx += 1\n",
        "    plt.show()\n",
        "\n",
        "plot_images_labels_prediction(x_test_image, y_test_label, 0, 25)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOHKHUMp30j8"
      },
      "source": [
        "Finally, we use a function to plot the test images along with their predicted labels. This will give us a visual representation of how well our model is performing.\n",
        "\n",
        "That's it! We have successfully trained a quantization-aware model, converted it to the TFLite format, and performed inference using the TensorFlow Lite interpreter.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywhXM1mA-a7F"
      },
      "source": [
        "# Convert your model to Orion's Cairo code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wP_kVSuEKA1U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"q_aware_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Create an object that with all weights and biases\n",
        "params = {\n",
        "    \"input\": x_test_image[0],\n",
        "    \"fc1_weights\": interpreter.get_tensor(1), \n",
        "    \"fc1_bias\": interpreter.get_tensor(2), \n",
        "    \"fc2_weights\": interpreter.get_tensor(4), \n",
        "    \"fc2_bias\": interpreter.get_tensor(5)\n",
        "}\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs('src/generated', exist_ok=True)\n",
        "\n",
        "for param_name, param in params.items():\n",
        "    with open(os.path.join('src', 'generated', f\"{param_name}.cairo\"), \"w\") as f:\n",
        "        f.write(\n",
        "            \"use array::ArrayTrait;\\n\" +\n",
        "            \"use orion::operators::tensor::core::{TensorTrait, Tensor};\\n\" +\n",
        "            \"use orion::operators::tensor::implementations::impl_tensor_i32;\\n\" +\n",
        "            \"use orion::numbers::signed_integer::i32::i32;\\n\\n\" +\n",
        "            \"fn {0}() -> Tensor<i32> \".format(param_name) + \"{\\n\" +\n",
        "            \"    let mut shape = ArrayTrait::<usize>::new();\\n\"\n",
        "        )\n",
        "        for dim in param.shape:\n",
        "            f.write(\"    shape.append({0});\\n\".format(dim))\n",
        "        f.write(\n",
        "            \"    let mut data = ArrayTrait::<i32>::new();\\n\"\n",
        "        )\n",
        "        for val in np.nditer(param.flatten()):\n",
        "            f.write(\"    data.append(i32 {{ mag: {0}, sign: {1} }});\\n\".format(abs(int(val)), str(val < 0).lower()))\n",
        "        f.write(\n",
        "            \"    TensorTrait::new(shape.span(), data.span())\\n\" +\n",
        "            \"}\\n\"\n",
        "        )\n",
        "      \n",
        "with open(os.path.join('src', 'generated.cairo'), 'w') as f:\n",
        "    for param_name in params.keys():\n",
        "        f.write(f\"mod {param_name};\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nKiq8oKxklon",
        "ix3qnUgElDlB",
        "7Bu55FCqlbj4",
        "XhbweTQEmWN-",
        "zxGWitSs3MAH"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
